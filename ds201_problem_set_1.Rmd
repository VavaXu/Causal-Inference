---
title: 'DS-UA 201: Problem Set 1'
author: "YOUR NAME"
date: "September 29, 2020"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


> This problem set is due at **11:59 pm on Tuesday, September 29th**. The data are on the course website. 

> Please upload your solutions as a .pdf file saved as `Yourlastname_Yourfirstinitial_pset1.pdf`). In addition, an electronic copy of your .Rmd file (saved as `Yourlastname_Yourfirstinitial_pset1.Rmd`) must be submitted to the course website at the same time. We should be able to run your code without error messages. Please note on your problem set if you collaborated with another student and, if so, whom. In order to receive credit, homework submissions must be substantially started and all work must be shown. Late assignments will not be accepted.


# Problem 1

Researchers often want to aggregate and synthesize evidence from multiple studies of the same question to get a more precise estimate of the effect of a particular intervention. These sorts of studies are called *meta-analyses* and are very common in medical and psychological research where many experiments of varying size are often run in many different contexts. 

We are going to replicate a meta-analysis using an example dataset from the *meta* suite in Stata of a series of experiments analyzing the effect of teacher expectations on student performance (*pupiliq.dta*). 

From the description of the data available [here](https://www.stata.com/manuals/meta.pdf) (pp. 19)

> This example describes a well-known study of Rosenthal and Jacobson (1968) that found the so-called Pygmalion effect, in which expectations of teachers affected outcomes of their students. A group of students was tested and then divided randomly into experimentals and controls. The division may have been random, but the teachers were told that the students identified as experimentals were likely to show dramatic intellectual growth. A few months later, a test was administered again to the entire group of students. The experimentals outperformed the controls. Subsequent researchers attempted to replicate the results, but many did not find the hypothesized effect.

> Raudenbush (1984) did a meta-analysis of 19 studies and hypothesized that the Pygmalion effect might be mitigated by how long the teachers had worked with the students before being told about the nonexistent higher expectations for the randomly selected subsample of students.

We will be working with the Raudenbush data set in R. First, load the data via the function `read_dta` from the `haven` package (part of the broader `tidyverse`).


```{r, echo=T, message=F}

### Read in the tidyverse
library(tidyverse)

### Load in the haven package
library(haven)

### Read in the pupiliq data
pupil <- read_dta("pupiliq.dta")
```


This dataset contains the results of 19 replications of the teacher expectation experiment. The relevant variables you will need are:

- `studylbl` - Author and date of the study
- `stdmdiff` - Estimated standardized average effect (difference between treated and control)
- `se` - Standard error of `stdmdiff`

### Part A

Consider the case of $K$ independent studies. Let $\hat{\tau_i}$ denote each study $i$'s estimator of the effect and $\sigma_i$ the **known**, **constant** standard error of that estimator (assume that we know the true standard error).

One approach to a meta-analysis assumes that each $\hat{\tau_i}$ is an unbiased estimator of a common effect parameter $\tau$ and that differences between studies are attributable to sampling error.

Consider the proposed combined estimator $\hat{\tau}$

$$\hat{\tau} = \frac{\sum_{i = 1}^K  \frac{1}{\sigma_i^2} \hat{\tau_i}}{\sum_{i = 1}^K  \frac{1}{\sigma_i^2}} $$
Find the expectation of $\hat{\tau}$. Is it an unbiased estimator of $\tau$?

### Part B

Find the variance of $\hat{\tau}$ (under the assumption that $\sigma_i$ is known for all $i$).  

### Part C

With this estimator, $\hat{\tau}$, generate a point estimate for $\tau$ using the 19 studies in the `pupiliq.dta` dataset and construct a 95\% confidence interval (assuming asymptotic normality).

### Part D

How does your estimate from C compare to the results from the Rosenthal \& Jacobson, 1968 study (study 17 in the `pupiliq.dta` dataset)?

### Part E

Suppose instead that someone suggested an alternate estimator for $\tau$, denoted $\widehat{\tau^{\prime}}$, that simply averaged all $K$ studies.

$$\widehat{\tau^{\prime}} =  \frac{1}{K} \sum_{i = 1}^K \hat{\tau_i}$$
Find the expectation and variance of this estimator. 

### Part F

With this alternate estimator, generate a point estimate and 95\% confidence interval (again assuming asymptotic normality) for $\tau$ using the 19 studies in the `pupiliq.dta` dataset. 

### Part G

How do the two estimators $\widehat{\tau^{\prime}}$ and $\hat{\tau}$ compare? Which would you prefer to use and why?

# Problem 2

Many studies in political science have documented an effect of *ballot order* on a candidate's vote share in an election.[^1] In general, candidates that are listed first on a ballot receive a slightly higher vote share than those listed lower on the ballot. As a result, most states will randomize the order of candidates on the ballot and alter the order from ballot to ballot.

In the 2008 Democratic Primary in New Hampshire, the ballot order was the same on all ballots. Furthermore, this fixed order was decided by randomly and unformly drawing a letter of the alphabet (A-Z) and then listing all candidates alphabetically by last name starting from the randomly chosen letter (and returning back to A after Z). In the actual primary election in 2008, the letter "Z" was drawn and therefore Joe Biden was first on all ballots. 

Professor Jon Krosnick of Stanford University noted in an [op-ed](https://abcnews.go.com/PollingUnit/Decision2008/story?id=4107883&page=1) that this process may have advantaged some candidates more than others ex-ante due to the distribution of last names on the ballot.

A total of 21 candidates were on the ballot in this election (ordered by last name below)

| Name |
|------|
|Biden|
|Caligiuri|
|Capalbo|
|Clinton|
|Crow|
|Dodd|
|Edwards|
|Gravel|
|Hewes|
|Hughes|
|Hunter|
|Keefe|
|Killeen|
|Koon|
|Kucinich|
|LaMagna|
|Laughlin|
|Obama|
|Richardson|
|Savior|
|Skok|

[^1]:  See, for example, Miller, Joanne M., and Jon A. Krosnick. "The impact of candidate name order on election outcomes." Public Opinion Quarterly (1998): 291-330; Ho, Daniel E., and Kosuke Imai. "Estimating causal effects of ballot order from a randomized natural experiment: The California alphabet lottery, 1978-2002." Public Opinion Quarterly 72.2 (2008): 216-240.

### Part A

Given the New Hampshire randomization process, what is the probability of Biden appearing as the first name on the ballot?

### Part B

What is the probability of Obama appearing as the first name on the ballot?

### Part C

Pollsters at the time noticed that the New Hampshire results in 2008 were significantly different from the average of polls leading up to the election. While Hillary Clinton finished 3 percentage points ahead of Barack Obama, the average of final poll estimates suggested Obama leading Clinton by 7 percentage points.[^2] In his op-ed, Krosnick suggested that Clinton may have beneffited in part from a ballot order effect. Given the New Hampshire randomization scheme, what is the probability of Hillary Clinton appearing above Barack Obama on the ballot?

[^2]: [An Evaluation of the Methodology of the
2008 Pre-Election Primary Polls](https://www.aapor.org/AAPOR_Main/media/MainSiteFiles/AAPOR_Rept_FINAL-Rev-4-13-09.pdf) 

# Problem 3

The STAR (Student-Teacher Achievement Ratio) Project was a four-year longitudinal study conducted on students in Tennessee to evaluate the impact of small class sizes on student achievement.[^3] The experiment began in 1985 and followed a single group of students from kindergarten to third grade. Students were randomly assigned to one of three types of classes: small classes (13-17 students per teacher), regular classes (22-25 students per teacher), and regular classes that were also assigned a teacher aide. Regular measures of achievement and other outcomes were taken annually during the four years of the study. Additionally, follow-up studies examined outcomes at later stages (such as high-school graduation).

In this problem, we'll analyze a portion of this dataset found in the Imai *Quantitative Social Science* book. You can load it in from the `STAR.csv` file using the `read_csv` function from the `haven` package.

```{r, echo=T, message=F}

### Read in the star data
star <- read_csv("STAR.csv")

```

This dataset contains 6325 observations of students. The relevant variables you will need are:

- `race` - Student's race: (coded as 1 = white, 2 = Black, 3 = Asian, 4 = Hispanic, 5 = Native American, 6 = Other)
- `classtype` - Assigned class size treatment in kindergarten (1 = small, 2 = regular, 3 = regular with aide)
- `yearssmall` - Number of years in a small-sized class (kindergarten through 3rd grade)
- `hsgrad` - Did the student graduate from from high school (1 = did graduate, 0 = did not graduate)
- `g4math` - Math score on the fourth-grade standardized test
- `g4reading` - Reading score on the fourth-grade standardized test

[^3]: For more on the study, see: Mosteller, Frederick. ``The Tennessee study of class size in the early school grades.'' *The future of children* (1995): 113-127.


### Part A

First, recode the `race` and `classtype` variables into factor/character variables based on the coding scheme described above. For both of these variables, you should have a new variable in your dataset that converts the numeric coding into an informative category name (e.g. "Black" instead of 2 for the `race` variable). Subset the data to only white and Black students. We'll be using this subset of the data for the remainder of the problem.

Using this dataset, create a summary table for the number of students assigned to each class type in kindergarten. Which of the three treatments has the fewest number of students assigned to it?

### Part B

Drop all observations with missing fourth-grade math scores **or** missing fourth-grade reading scores. Using this dataset of complete observations, estimate the average treatment effects of being assigned to a small kindergarten class versus being assigned to a regular kindergarten class (with no aide) on fourth-grade math and fourth-grade reading scores. Calculate the large-sample (Neyman) standard error and provide a 95\% asymptotic confidence interval for each of your estimates. Would you reject the null of no average treatment effect on math scores at the $\alpha = 0.05$ level? Would you reject for the effect on reading scores? Interpret your findings and compare the two estimated effects. What do you conclude about the effect of small kindergarten class sizes on average test scores?

### Part C

If treatment were randomly assigned, we would expect to see balance between the different treatment conditions on pre-treatment covariates. Here, we want to investigate whether the different treatment groups have similar proportions of white and Black students. To do so, we'll perform a *balance check*. Calculate the proportion of Black students in each of the three treatment groups for kindergarten class size. Do the treatment arms all have similar proportions of Black students?

### Part D

In this part, we'll look instead at whether students graduate high school. Starting with the complete dataset of white and Black students, create a new dataset that removes all students with missing values of `hsgrad`. For now we'll assume that the `hsgrad` variable is missing completely at random and subset the data to only observations where that variable is non-missing.

Suppose we were interested in the effect of repeated exposure to small class sizes and not just the effect of small class sizes in kindergarten. In this new dataset, create a variable for each student that takes on a value of $1$ if that student had more than 2 years of small class sizes and a value of $0$ otherwise. Assuming that this new "treatment" is as-good-as-randomly assigned, estimate the average treatment effect of having 3 or 4 years of small class sizes from kindergarten to third grade on the probability that a student graduates high school. Provide a 95\% asymptotic confidence interval and interpret your results. Do you reject the null of no average treatment effect at the $\alpha = .05$ level? Interpret your result.

### Part E

Examine whether the "years of small class sizes" variable is balanced on race. Are Black students in the study any more or less likely to have more than 2 years of small class sizes from kindergarten to grade three compared to white students in the study?

Given your findings here, is the assumption of unconfoundedness/ignorability for the "years of small class sizes" variable reasonable? Should we interpret the estimate from Part D causally?
